{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from standoffconverter import Standoff, View\n",
    "import json\n",
    "from spacy.lang.fr import French\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Corpus Charles Bruneau for ML\n",
    "\n",
    "In this notebook, we demonstrate how to use the standoff converter to apply ML methods in the context of an existing TEI edition. It is shown how to load the given TEI XML file and parse it into a standoff format of the standoff converter. How to extract a plain text view from the edition and how it is split into sentences using the spacy NLP library. Crucially, it is shown how the detected sentences are (1) added to the TEI and (2) prepared as a CSV file for further analysis or manual labelling. In both output formats, the same identifier is used for a given sentence so that future annotation from an ML model can be added to the TEI, easily.\n",
    "\n",
    "## Loading the XML\n",
    "First, the XML file is loaded as an `lxml.etree`. Then, a `standoffconverter.Standoff` object is created that takes the `etree` as input. In the `Standoff` object, the standoff representation and the `etree` representation are always kept in sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 context          text\n",
      "0      [[[<Element {http://www.tei-c.org/ns/1.0}pb at...        \\n    \n",
      "1      [[[<Element {http://www.tei-c.org/ns/1.0}pb at...      \\n      \n",
      "2      [[[<Element {http://www.tei-c.org/ns/1.0}pb at...              \n",
      "3      [[[<Element {http://www.tei-c.org/ns/1.0}pb at...      \\n      \n",
      "4      [[[<Element {http://www.tei-c.org/ns/1.0}pb at...    \\n        \n",
      "...                                                  ...           ...\n",
      "27817  [[[<Element {http://www.tei-c.org/ns/1.0}pb at...  \\n          \n",
      "27818  [[[<Element {http://www.tei-c.org/ns/1.0}pb at...    \\n        \n",
      "27819  [[[<Element {http://www.tei-c.org/ns/1.0}pb at...      \\n      \n",
      "27820  [[[<Element {http://www.tei-c.org/ns/1.0}pb at...        \\n    \n",
      "27821  [[[<Element {http://www.tei-c.org/ns/1.0}pb at...          \\n  \n",
      "\n",
      "[27822 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "parser=etree.XMLParser(remove_comments=True)\n",
    "tree = etree.fromstring(open(\"indir/charles-destinataires.xml\").read(), parser=parser)\n",
    "so = Standoff(tree, namespaces={\n",
    "    \"tei\":\"http://www.tei-c.org/ns/1.0\"\n",
    "})\n",
    "print(so.collapsed_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the plain text view\n",
    "After loading the TEI XML, we need to extract a plain text view from the XML file. This can be a demanding scholarly task, for example in the case of genetic editions where the XML file may contain countless variants of the document. In this case, we just focus on the main body of the text that is inside the `<div1>` tags and we remove comments (in XML, denoted by `<!-- .. -->`) and shrink longer sequences of white space to single whitespace characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create view: 100%|██████████| 37158/37158 [00:17<00:00, 2095.27it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 210.10it/s]\n",
      "shrink whitespace: 100%|██████████| 760188/760188 [03:05<00:00, 4103.42it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "view = (\n",
    "    View(so)\n",
    "        .exclude_outside(\"{http://www.tei-c.org/ns/1.0}div1\")\n",
    "        .shrink_whitespace()\n",
    "        .remove_comments()\n",
    ")\n",
    "\n",
    "plain = view.get_plain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split plain text view into sentences\n",
    "Now we are ready to apply spacy to the plain text view to split it into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8b788822744af3a820274a5efea5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = French()\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "sentences = []\n",
    "for sent in tqdm(nlp(plain).sents):\n",
    "    sentences.append(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add resulting sentence tags to the TEI\n",
    "The most important part of the standoff converter package is that it keeps the reference of each character mapping from the position in the plain text view to the position in the TEI document. Here, we get the position in the standoff data structure from the position in the plain text view: `start_ind = view.get_table_pos(sent.start_char)`. Then, we can add `<s>` tags to the TEI document using the `so.add_inline` command!\n",
    "Since the TEI document is required to keep the tree characteristic, sometimes. It is not possible to add a new inline element. Whenever the inline element cannot be created, we use a `<span>`-`<anchor>` combination that does not break the tree characteristic of the document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1943b33224b54c048886b9a99cdcecb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8219.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for isent, sent in tqdm(enumerate(sentences), total=len(sentences)):\n",
    "\n",
    "    start_ind = view.get_table_pos(sent.start_char)\n",
    "    end_ind = view.get_table_pos(sent.end_char-1)+1\n",
    "    try:\n",
    "        so.add_inline(\n",
    "            begin=start_ind,\n",
    "            end=end_ind,\n",
    "            tag=\"s\",\n",
    "            depth=None,\n",
    "            attrib={'id':f'{isent}'}\n",
    "        )\n",
    "    except ValueError:\n",
    "        so.add_span(\n",
    "            begin=start_ind,\n",
    "            end=end_ind,\n",
    "            tag=\"s\",\n",
    "            depth=None,\n",
    "            attrib={'id':f'{isent}'},\n",
    "            id_=f'{isent}-anchor'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the resulting files\n",
    "We now create two output files. We save the sentencized version of the TEI XML as a file. As you can see, the corresponding id is stored as a tag attribute. Also, we save the data set as a jsonl file. This format is following the schema that is expected by the open source labelling tool doccano https://doccano.herokuapp.com/. This way, the sentences can be added to the labellingi tool to create manual labels that can later be used to train a new ML-model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<text xmlns=\"http://www.tei-c.org/ns/1.0\">\n",
      "    <front>\n",
      "      <pb xml:id=\"page-000a\" facs=\"./facs/p_000a.jpg\"/>\n",
      "      <titlePage>\n",
      "        <docTitle>\n",
      "          <titlePart>Ma Guerre<lb/>1914-1918</titlePart>\n",
      "        </docTitle>\n",
      "        <byline>par <lb/><docAuthor>Charles Bruneau</docAuthor></byline>\n",
      "      </titlePage>\n",
      "      <pb xml:id=\"page-000b\" facs=\"./facs/p_000b.jpg\"/>\n",
      "      <epigraph>\n",
      "        <quote>\"Ne croyez pas aux dires du Poilu quand il se<lb/> \"m&#234;le de juger d'un combat. Pensez\n",
      "          qu'il vous<lb/> \"&#233;crit le ventre garni, s'il dit que tout va<lb/> \"bien; que son soulier\n",
      "          lui fait mal ou qu'il<lb/> \"n'a pas dormi, s'il affirme que rien ne va<lb/> \"plus\n",
      "          .\"</quote>\n",
      "        <bibl><author>J. ARENE</author><lb/> (<title>Les Carnets d'un soldat en Haute-Alsace et<lb/>\n",
      "            dans les Vosges</title>\n",
      "          <biblScope>p.15</biblScope>). </bibl>\n",
      "      </epigraph>\n",
      "      <pb xml:id=\"page-001\" facs=\"./facs/p_001.jpg\"/>\n",
      "      <div1 type=\"section\" xml:id=\"intro\"><s spanTo=\"0-anchor\" id=\"0\"/>\n",
      "        <head>Introduction</head>\n",
      "        <p>Je n'ai pas l'intention de publier ces \"M&#233;moires\";<lb/> au cours de cette guerre, je n'ai\n",
      "          rien fait et je n'ai rien<lb/> vu qui puisse justifier cette publication.<anchor id=\"0-anchor\"/> <s id=\"1\">J'ai v&#233;cu la\n",
      "          vie<lb/> qu'ont v&#233;cu des millions d'autres Fran&#231;ais - des millions d'au<lb break=\"no\" rend=\"hyphen\"/>tres hommes.</s> <s id=\"2\">Plus tard, je serai heureux sans doute de relire<lb/> ces\n",
      "          pages, et ceux qui s'int&#233;ressent &#224; moi peuvent y prendre<lb/> int&#233;r&#234;t.</s> <s id=\"3\">Le public, satur&#233;\n",
      "          d'ailleurs par de nombreuses publica<lb break=\"no\" rend=\"hyphen\"/>tions sur la guerre, ne\n",
      "          pourrait y trouver rien de neuf.</s></p>\n",
      "\n",
      "        <p><s id=\"4\">Je craindrais d'ailleurs que le souci de la publica<lb break=\"no\" rend=\"hyphen\"/>tion ne\n",
      "          v&#238;nt modifier le ton de ces m&#233;moires ou m&#234;me en alt&\n"
     ]
    }
   ],
   "source": [
    "print(etree.tostring(so.text_el, pretty_print=True).decode('utf-8')[:2000])\n",
    "\n",
    "with open(\"outdir/sentencized_charles-destinataires.xml\", \"w\") as fout:\n",
    "    fout.write(\n",
    "        etree.tostring(so.tree, pretty_print=True).decode('utf-8')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outdir/dataset.jsonl\", \"w\") as fout:\n",
    "    out_data = []\n",
    "    for isentence, sentence in enumerate(sentences):\n",
    "        out_data.append(json.dumps({\n",
    "            \"text\": sentence.text,\n",
    "            \"labels\": [],\n",
    "            \"meta\": {\"sentenceId\": f\"{isentence}\"}\n",
    "        }))\n",
    "    fout.write(\"\\n\".join(out_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in this screenshot from doccano, the sentence id is preserved in the meta data of each doccano record:\n",
    "![screenshot from doccano showing a few sentences from the edition.](doccano_screenshot.png \"screenshot from doccano showing a few sentences from the edition.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-env",
   "language": "python",
   "name": "main-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
